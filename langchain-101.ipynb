{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import END, MessageGraph\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "LANGCHAIN_ENDPOINT = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "LANGCHAIN_PROJECT = os.getenv(\"LANGCHAIN_PROJECT\")  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =  ChatGroq(temperature=1, model_name=\"llama3-70b-8192\", api_key=groq_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.globals import set_debug\n",
    "from langchain.globals import set_verbose\n",
    "\n",
    "set_verbose(False)\n",
    "set_debug(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+  \n",
      "| __start__ |  \n",
      "+-----------+  \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      "  +--------+   \n",
      "  | oracle |   \n",
      "  +--------+   \n",
      "      *        \n",
      "      *        \n",
      "      *        \n",
      " +---------+   \n",
      " | __end__ |   \n",
      " +---------+   \n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "graph.add_node(\"oracle\", model)\n",
    "graph.add_edge(\"oracle\", END)\n",
    "\n",
    "graph.set_entry_point(\"oracle\")\n",
    "\n",
    "runnable = graph.compile()\n",
    "\n",
    "runnable.get_graph().print_ascii()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is 1 + 1?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > llm:ChatGroq] [3.94s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"1 + 1 is 2.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"1 + 1 is 2.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_time\": 0.027,\n",
      "                \"completion_tokens\": 8,\n",
      "                \"prompt_time\": 0.053,\n",
      "                \"prompt_tokens\": 18,\n",
      "                \"queue_time\": null,\n",
      "                \"total_time\": 0.08,\n",
      "                \"total_tokens\": 26\n",
      "              },\n",
      "              \"model_name\": \"llama3-70b-8192\",\n",
      "              \"system_fingerprint\": \"fp_c1a4bcec29\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-b39b8378-ed42-4e55-bfbe-2af7a2ee2aef-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_time\": 0.027,\n",
      "      \"completion_tokens\": 8,\n",
      "      \"prompt_time\": 0.053,\n",
      "      \"prompt_tokens\": 18,\n",
      "      \"queue_time\": null,\n",
      "      \"total_time\": 0.08,\n",
      "      \"total_tokens\": 26\n",
      "    },\n",
      "    \"model_name\": \"llama3-70b-8192\",\n",
      "    \"system_fingerprint\": \"fp_c1a4bcec29\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<oracle,__root__>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<oracle,__root__>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle] [3.95s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [3.95s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 1 + 1?', id='aa752065-0527-4299-bc69-cb73c334330c'),\n",
       " AIMessage(content='1 + 1 is 2.', response_metadata={'token_usage': {'completion_time': 0.027, 'completion_tokens': 8, 'prompt_time': 0.053, 'prompt_tokens': 18, 'queue_time': None, 'total_time': 0.08, 'total_tokens': 26}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_c1a4bcec29', 'finish_reason': 'stop', 'logprobs': None}, id='run-b39b8378-ed42-4e55-bfbe-2af7a2ee2aef-0')]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke(HumanMessage(\"What is 1 + 1?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "@tool\n",
    "def multiply(first_number: int, second_number: int):\n",
    "    \"\"\"Multiplies two numbers together.\"\"\"\n",
    "    return first_number * second_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_tools = model.bind_tools([multiply])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = MessageGraph()\n",
    "\n",
    "builder.add_node(\"oracle\", model_with_tools)\n",
    "\n",
    "tool_node = ToolNode([multiply])\n",
    "builder.add_node(\"multiply\", tool_node)\n",
    "\n",
    "builder.add_edge(\"multiply\", END)\n",
    "\n",
    "builder.set_entry_point(\"oracle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from typing import List, Literal\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "def router(state: List[BaseMessage]) -> Literal[\"multiply\", \"__end__\"]:\n",
    "    tool_calls = state[-1].additional_kwargs.get(\"tool_calls\", [])\n",
    "    if len(tool_calls):\n",
    "        return \"multiply\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "\n",
    "builder.add_conditional_edges(\"oracle\", router)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: What is 123 * 456?\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in ConsoleCallbackHandler.on_tool_end callback: AttributeError(\"'int' object has no attribute 'strip'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > llm:ChatGroq] [1.80s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"tool_calls\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"tool_calls\": [\n",
      "                {\n",
      "                  \"id\": \"call_gv29\",\n",
      "                  \"function\": {\n",
      "                    \"arguments\": \"{\\\"first_number\\\":123,\\\"second_number\\\":456}\",\n",
      "                    \"name\": \"multiply\"\n",
      "                  },\n",
      "                  \"type\": \"function\"\n",
      "                }\n",
      "              ]\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_time\": 0.219,\n",
      "                \"completion_tokens\": 123,\n",
      "                \"prompt_time\": 0.335,\n",
      "                \"prompt_tokens\": 1135,\n",
      "                \"queue_time\": null,\n",
      "                \"total_time\": 0.554,\n",
      "                \"total_tokens\": 1258\n",
      "              },\n",
      "              \"model_name\": \"mixtral-8x7b-32768\",\n",
      "              \"system_fingerprint\": \"fp_c5f20b5bb1\",\n",
      "              \"finish_reason\": \"tool_calls\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-62246cc3-d15d-4951-acae-a98bdd80a7f9-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"multiply\",\n",
      "                \"args\": {\n",
      "                  \"first_number\": 123,\n",
      "                  \"second_number\": 456\n",
      "                },\n",
      "                \"id\": \"call_gv29\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_time\": 0.219,\n",
      "      \"completion_tokens\": 123,\n",
      "      \"prompt_time\": 0.335,\n",
      "      \"prompt_tokens\": 1135,\n",
      "      \"queue_time\": null,\n",
      "      \"total_time\": 0.554,\n",
      "      \"total_tokens\": 1258\n",
      "    },\n",
      "    \"model_name\": \"mixtral-8x7b-32768\",\n",
      "    \"system_fingerprint\": \"fp_c5f20b5bb1\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<oracle,__root__>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<oracle,__root__>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:router] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:router] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"multiply\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<branch:oracle:router:multiply>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<branch:oracle:router:multiply>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle] [1.80s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:multiply] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:multiply > tool:multiply] Entering Tool run with input:\n",
      "\u001b[0m\"{'first_number': 123, 'second_number': 456}\"\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:multiply > chain:ChannelWrite<multiply,__root__>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:multiply > chain:ChannelWrite<multiply,__root__>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:multiply] [3ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [1.81s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 123 * 456?', id='14537f36-42f8-4672-aa3c-e25d6e4df3a1'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_gv29', 'function': {'arguments': '{\"first_number\":123,\"second_number\":456}', 'name': 'multiply'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_time': 0.219, 'completion_tokens': 123, 'prompt_time': 0.335, 'prompt_tokens': 1135, 'queue_time': None, 'total_time': 0.554, 'total_tokens': 1258}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-62246cc3-d15d-4951-acae-a98bdd80a7f9-0', tool_calls=[{'name': 'multiply', 'args': {'first_number': 123, 'second_number': 456}, 'id': 'call_gv29'}]),\n",
       " ToolMessage(content='56088', name='multiply', id='acd80e1d-4fbf-432a-b4df-c3157dbf855d', tool_call_id='call_gv29')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable = builder.compile()\n",
    "\n",
    "runnable.invoke(HumanMessage(\"What is 123 * 456?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +-----------+      \n",
      "          | __start__ |      \n",
      "          +-----------+      \n",
      "                 *           \n",
      "                 *           \n",
      "                 *           \n",
      "            +--------+       \n",
      "            | oracle |       \n",
      "            +--------+       \n",
      "           ..         ..     \n",
      "         ..             ..   \n",
      "        .                 .. \n",
      "+----------+                .\n",
      "| multiply |              .. \n",
      "+----------+            ..   \n",
      "           **         ..     \n",
      "             **     ..       \n",
      "               *   .         \n",
      "            +---------+      \n",
      "            | __end__ |      \n",
      "            +---------+      \n"
     ]
    }
   ],
   "source": [
    "runnable.get_graph().print_ascii()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.graph import CurveStyle, NodeColors, MermaidDrawMethod\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        runnable.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > llm:ChatGroq] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: create 10 unique names that incorporate elements of Greek mythology and playful twists, you can follow these steps:\\nCombine with Modern Elements: Mix these mythological names with modern or technological terms that would cover any service from outsourcing \\ncleaning for hotel rooms down to air traffic control, network engineers, software developers, kitchen cheffs, restaurant waiters, etc. \\nPlayful Twists and Modifications: Modify the names slightly to make them unique or to fit better with the modern elements you've chosen. \\nEnsure Uniqueness: Make sure each name is distinct from the others by varying the mythological component or the modern term and joyfull\\nand easy to remember\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > llm:ChatGroq] [1.87s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"Here are 10 unique names that incorporate elements of Greek mythology and playful twists:\\n\\n1. **ZeusByte** (Zeus + Byte) - perfect for a software development company that's powerful and efficient.\\n2. **AuroraNet** (Aurora + Network) - suitable for a network engineering firm that brings light and connectivity to its clients.\\n3. **HermesDeliver** (Hermes + Deliver) - ideal for a food delivery or logistics company that's fast and reliable.\\n4. **AthenaTech** (Athena + Tech) - great for a technology consulting firm that's wise and innovative.\\n5. **PoseidonPro** (Poseidon + Pro) - suitable for a professional cleaning service that's powerful and thorough, like the sea god.\\n6. **DianaDish** (Diana + Dish) - perfect for a restaurant or catering company that's swift and delicious, like the goddess of the hunt.\\n7. **HephaestusHelp** (Hephaestus + Help) - ideal for a technical support or IT services company that's skilled and reliable, like the Greek god of the forge.\\n8. **ArtemisAir** (Artemis + Air) - suitable for an air traffic control or aviation services company that's swift and precise, like the goddess of the hunt.\\n9. **DemeterDesk** (Demeter + Desk) - great for a coworking space or virtual office company that's nurturing and productive, like the goddess of agriculture.\\n10. **ChronoCare** (Chronos + Care) - perfect for a healthcare or medical services company that's timely and attentive, like the Greek god of time.\\n\\nEach name incorporates elements of Greek mythology and playful twists, making them unique, memorable, and easy to associate with the services they represent.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"Here are 10 unique names that incorporate elements of Greek mythology and playful twists:\\n\\n1. **ZeusByte** (Zeus + Byte) - perfect for a software development company that's powerful and efficient.\\n2. **AuroraNet** (Aurora + Network) - suitable for a network engineering firm that brings light and connectivity to its clients.\\n3. **HermesDeliver** (Hermes + Deliver) - ideal for a food delivery or logistics company that's fast and reliable.\\n4. **AthenaTech** (Athena + Tech) - great for a technology consulting firm that's wise and innovative.\\n5. **PoseidonPro** (Poseidon + Pro) - suitable for a professional cleaning service that's powerful and thorough, like the sea god.\\n6. **DianaDish** (Diana + Dish) - perfect for a restaurant or catering company that's swift and delicious, like the goddess of the hunt.\\n7. **HephaestusHelp** (Hephaestus + Help) - ideal for a technical support or IT services company that's skilled and reliable, like the Greek god of the forge.\\n8. **ArtemisAir** (Artemis + Air) - suitable for an air traffic control or aviation services company that's swift and precise, like the goddess of the hunt.\\n9. **DemeterDesk** (Demeter + Desk) - great for a coworking space or virtual office company that's nurturing and productive, like the goddess of agriculture.\\n10. **ChronoCare** (Chronos + Care) - perfect for a healthcare or medical services company that's timely and attentive, like the Greek god of time.\\n\\nEach name incorporates elements of Greek mythology and playful twists, making them unique, memorable, and easy to associate with the services they represent.\",\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_time\": 1.258,\n",
      "                \"completion_tokens\": 378,\n",
      "                \"prompt_time\": 0.101,\n",
      "                \"prompt_tokens\": 143,\n",
      "                \"queue_time\": null,\n",
      "                \"total_time\": 1.359,\n",
      "                \"total_tokens\": 521\n",
      "              },\n",
      "              \"model_name\": \"llama3-70b-8192\",\n",
      "              \"system_fingerprint\": \"fp_c1a4bcec29\",\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2ad3a8c7-fdd9-4180-b40e-b9b56c965fc9-0\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_time\": 1.258,\n",
      "      \"completion_tokens\": 378,\n",
      "      \"prompt_time\": 0.101,\n",
      "      \"prompt_tokens\": 143,\n",
      "      \"queue_time\": null,\n",
      "      \"total_time\": 1.359,\n",
      "      \"total_tokens\": 521\n",
      "    },\n",
      "    \"model_name\": \"llama3-70b-8192\",\n",
      "    \"system_fingerprint\": \"fp_c1a4bcec29\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<oracle,__root__>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle > chain:ChannelWrite<oracle,__root__>] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:oracle] [1.87s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [1.87s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    }
   ],
   "source": [
    "the_question=\"\"\"create 10 unique names that incorporate elements of Greek mythology and playful twists, you can follow these steps:\n",
    "Combine with Modern Elements: Mix these mythological names with modern or technological terms that would cover any service from outsourcing \n",
    "cleaning for hotel rooms down to air traffic control, network engineers, software developers, kitchen cheffs, restaurant waiters, etc. \n",
    "Playful Twists and Modifications: Modify the names slightly to make them unique or to fit better with the modern elements you've chosen. \n",
    "Ensure Uniqueness: Make sure each name is distinct from the others by varying the mythological component or the modern term and joyfull\n",
    "and easy to remember\"\"\"\n",
    "answer = runnable.invoke(HumanMessage(the_question))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 unique names that incorporate elements of Greek mythology and playful twists:\n",
      "\n",
      "1. **ZeusByte** (Zeus + Byte) - perfect for a software development company that's powerful and efficient.\n",
      "2. **AuroraNet** (Aurora + Network) - suitable for a network engineering firm that brings light and connectivity to its clients.\n",
      "3. **HermesDeliver** (Hermes + Deliver) - ideal for a food delivery or logistics company that's fast and reliable.\n",
      "4. **AthenaTech** (Athena + Tech) - great for a technology consulting firm that's wise and innovative.\n",
      "5. **PoseidonPro** (Poseidon + Pro) - suitable for a professional cleaning service that's powerful and thorough, like the sea god.\n",
      "6. **DianaDish** (Diana + Dish) - perfect for a restaurant or catering company that's swift and delicious, like the goddess of the hunt.\n",
      "7. **HephaestusHelp** (Hephaestus + Help) - ideal for a technical support or IT services company that's skilled and reliable, like the Greek god of the forge.\n",
      "8. **ArtemisAir** (Artemis + Air) - suitable for an air traffic control or aviation services company that's swift and precise, like the goddess of the hunt.\n",
      "9. **DemeterDesk** (Demeter + Desk) - great for a coworking space or virtual office company that's nurturing and productive, like the goddess of agriculture.\n",
      "10. **ChronoCare** (Chronos + Care) - perfect for a healthcare or medical services company that's timely and attentive, like the Greek god of time.\n",
      "\n",
      "Each name incorporates elements of Greek mythology and playful twists, making them unique, memorable, and easy to associate with the services they represent.\n"
     ]
    }
   ],
   "source": [
    "print(answer[1].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tools = [TavilySearchResults(max_results=2)]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "modelwith_tools = model.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated\n",
    "\n",
    "def add_messages(left: list, right: list):\n",
    "    \"\"\"Add-don't-overwrite.\"\"\"\n",
    "    return left + right\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    \n",
    "from typing import Literal\n",
    "\n",
    "# Define the function that determines whether to continue or not\n",
    "def should_continue(state: AgentState) -> Literal[\"action\", \"__end__\"]:\n",
    "    messages = state['messages']\n",
    "    last_message = messages[-1]\n",
    "    # If the LLM makes a tool call, then we route to the \"action\" node\n",
    "    if last_message.tool_calls:\n",
    "        return \"action\"\n",
    "    # Otherwise, we stop (reply to the user)\n",
    "    return \"__end__\"\n",
    "\n",
    "\n",
    "# Define the function that calls the model\n",
    "def call_model(state: AgentState):\n",
    "    messages = state['messages']\n",
    "    response = modelwith_tools.invoke(messages)\n",
    "    # We return a list, because this will get added to the existing list\n",
    "    return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the two nodes we will cycle between\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"action\", tool_node)\n",
    "\n",
    "# Set the entrypoint as `agent`\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# We now add a conditional edge\n",
    "workflow.add_conditional_edges(\n",
    "    # First, we define the start node. We use `agent`.\n",
    "    # This means these are the edges taken after the `agent` node is called.\n",
    "    \"agent\",\n",
    "    # Next, we pass in the function that will determine which node is called next.\n",
    "    should_continue,\n",
    ")\n",
    "\n",
    "# We now add a normal edge from `tools` to `agent`.\n",
    "# This means that after `tools` is called, `agent` node is called next.\n",
    "workflow.add_edge('action', 'agent')\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+           \n",
      "        | __start__ |           \n",
      "        +-----------+           \n",
      "               *                \n",
      "               *                \n",
      "               *                \n",
      "          +-------+             \n",
      "          | agent |             \n",
      "          +-------+             \n",
      "          *        ..           \n",
      "        **           ..         \n",
      "       *               .        \n",
      "+--------+         +---------+  \n",
      "| action |         | __end__ |  \n",
      "+--------+         +---------+  \n"
     ]
    }
   ],
   "source": [
    "app.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables.graph import CurveStyle, NodeColors, MermaidDrawMethod\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"Search in internet for this question: \" + the_question)]}\n",
    "results = app.invoke(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 10 unique names that incorporate elements of Greek mythology with modern twists:\n",
      "\n",
      "1. **Zeusra**: A combination of Zeus, the king of the gods, and \"ra\" from radar, suggesting advanced technology and surveillance systems.\n",
      "2. **AthenaCode**: A mix of Athena, the goddess of wisdom, and \"code,\" implying expertise in software development and programming.\n",
      "3. **PoseiTech**: A blend of Poseidon, the god of the sea, and \"tech,\" suggesting innovative solutions for marine conservation and oceanography.\n",
      "4. **HeraHub**: A combination of Hera, the queen of the gods, and \"hub,\" implying a central connection point for network engineers and IT specialists.\n",
      "5. **DemosKitchen**: A mix of Demos, the Greek word for \"people,\" and \"kitchen,\" suggesting a culinary expertise that caters to diverse tastes and cuisines.\n",
      "6. **ArtemisAir**: A combination of Artemis, the goddess of the hunt, and \"air,\" implying efficient and agile air traffic control systems.\n",
      "7. **Achilleanalytics**: A blend of Achilles, the legendary hero, and \"analytics,\" suggesting advanced data analysis and insights.\n",
      "8. **HestiaHost**: A combination of Hestia, the goddess of the hearth, and \"host,\" implying warm hospitality and hotel management expertise.\n",
      "9. **CerberusCare**: A mix of Cerberus, the three-headed dog, and \"care,\" suggesting protective and nurturing services for clients.\n",
      "10. **Oceanix**: A blend of Oceanus, the Titan of the ocean, and \"nix,\" implying innovative solutions for water management and conservation.\n",
      "\n",
      "These names aim to evoke the richness of Greek mythology while incorporating modern elements to create unique and memorable brand identities.\n"
     ]
    }
   ],
   "source": [
    "print(results['messages'][3].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can use the `find` command to achieve this. Here's an example:\n",
      "```\n",
      "find . -type f -name \"*.txt\" -mtime -30 -print\n",
      "```\n",
      "Let's break it down:\n",
      "\n",
      "* `.` is the current directory.\n",
      "* `-type f` specifies that we only want to consider files (not directories).\n",
      "* `-name \"*.txt\"` matches files with the `.txt` extension (adjust this pattern to match your specific needs).\n",
      "* `-mtime -30` selects files that have been modified within the last 30 days (i.e., in the last month).\n",
      "* `-print` simply prints the names of the matching files.\n",
      "\n",
      "When you run this command, you should see a list of text files in the current directory that have been modified in the last month.\n",
      "\n",
      "If you want to list files recursively (i.e., including subdirectories), add the `-recursive` option:\n",
      "```\n",
      "find . -type f -name \"*.txt\" -mtime -30 -recursive -print\n",
      "```\n",
      "Note that `-mtime` uses the file's modification time, which is the time the file's contents were last modified. If you want to consider the file's access time (i.e., when the file was last accessed), use `-atime` instead.\n",
      "{'token_usage': {'completion_time': 0.86, 'completion_tokens': 257, 'prompt_time': 0.098, 'prompt_tokens': 34, 'queue_time': None, 'total_time': 0.958, 'total_tokens': 291}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'stop', 'logprobs': None}\n"
     ]
    }
   ],
   "source": [
    "response_message = model.invoke(\n",
    "    \"In bash, how do I list all the text files in the current directory that have been modified in the last month?\"\n",
    ")\n",
    "\n",
    "print(response_message.content)\n",
    "print(response_message.response_metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
