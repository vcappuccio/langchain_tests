{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from git import Repo\n",
    "from langchain_community.document_loaders.generic import GenericLoader\n",
    "from langchain_community.document_loaders.parsers import LanguageParser  \n",
    "from langchain_text_splitters import Language, MarkdownTextSplitter\n",
    "import os\n",
    "\n",
    "# Imports\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain \n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "tavily_api_key = os.getenv(\"TAVILY_API_KEY\") \n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "langchain_endpoint = os.getenv(\"LANGCHAIN_ENDPOINT\")\n",
    "os.environ[\"COHERE_API_KEY\"] =  os.getenv(\"COHERE_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"git_runner\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize embeddings and model\n",
    "# embeddings = OllamaEmbeddings(model=\"mistral\", base_url=\"http://host.docker.internal:11434\")\n",
    "model = ChatGroq(temperature=1, model_name=\"llama3-70b-8192\", api_key=groq_api_key)\n",
    "embeddings = CohereEmbeddings(model=\"embed-english-light-v3.0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_chroma_db(repos_list, local_repo_path, db_path):\n",
    "    for repo_info in repos_list:\n",
    "        repo_path = os.path.join(local_repo_path, repo_info['name'])\n",
    "        # Check if the repository directory exists, if not, clone it\n",
    "        if not os.path.exists(repo_path):\n",
    "            Repo.clone_from(repo_info['url'], to_path=repo_path)\n",
    "        else:\n",
    "            print(f\"The directory '{repo_path}' already exists. Skipping cloning.\")\n",
    "            continue\n",
    "\n",
    "        core_path = os.path.join(repo_path)\n",
    "        # Load Python and Jupyter Notebook files\n",
    "        python_notebook_loader = GenericLoader.from_filesystem(\n",
    "            core_path,\n",
    "            suffixes=[\".py\", \".ipynb\", \".md\"],\n",
    "            exclude=[\"**/non-utf8-encoding.py\"],\n",
    "            parser=LanguageParser(parser_threshold=500),\n",
    "        )\n",
    "        python_documents = python_notebook_loader.load()\n",
    "\n",
    "        python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "            language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    "        )\n",
    "\n",
    "        texts = python_splitter.split_documents(python_documents)\n",
    "\n",
    "        return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidDimensionException",
     "evalue": "Embedding dimension 384 does not match collection dimensionality 4096",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidDimensionException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m repos_list \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124machainflow\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://github.com/vcappuccio/achainflow\u001b[39m\u001b[38;5;124m'\u001b[39m},\n\u001b[1;32m      7\u001b[0m ]\n\u001b[1;32m     10\u001b[0m texts\u001b[38;5;241m=\u001b[39m update_chroma_db(repos_list, local_repo_path, db_directory)\n\u001b[0;32m---> 11\u001b[0m vectordb \u001b[38;5;241m=\u001b[39m \u001b[43mChroma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdb_directory\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:791\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[0;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    789\u001b[0m texts \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[1;32m    790\u001b[0m metadatas \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpersist_directory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpersist_directory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:749\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mchromadb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbatch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_batches\n\u001b[1;32m    743\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m create_batches(\n\u001b[1;32m    744\u001b[0m         api\u001b[38;5;241m=\u001b[39mchroma_collection\u001b[38;5;241m.\u001b[39m_client,\n\u001b[1;32m    745\u001b[0m         ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    746\u001b[0m         metadatas\u001b[38;5;241m=\u001b[39mmetadatas,  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    747\u001b[0m         documents\u001b[38;5;241m=\u001b[39mtexts,\n\u001b[1;32m    748\u001b[0m     ):\n\u001b[0;32m--> 749\u001b[0m         \u001b[43mchroma_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_texts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    750\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtexts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    752\u001b[0m \u001b[43m            \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    755\u001b[0m     chroma_collection\u001b[38;5;241m.\u001b[39madd_texts(texts\u001b[38;5;241m=\u001b[39mtexts, metadatas\u001b[38;5;241m=\u001b[39mmetadatas, ids\u001b[38;5;241m=\u001b[39mids)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/langchain_chroma/vectorstores.py:328\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[0;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m ids_with_metadata \u001b[38;5;241m=\u001b[39m [ids[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m non_empty_ids]\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 328\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_collection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts_with_metadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids_with_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected metadata value to be\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/api/models/Collection.py:487\u001b[0m, in \u001b[0;36mCollection.upsert\u001b[0;34m(self, ids, embeddings, metadatas, documents, images, uris)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mimages)\n\u001b[0;32m--> 487\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_upsert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadatas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadatas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43muris\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muris\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/api/segment.py:465\u001b[0m, in \u001b[0;36mSegmentAPI._upsert\u001b[0;34m(self, collection_id, ids, embeddings, metadatas, documents, uris)\u001b[0m\n\u001b[1;32m    455\u001b[0m records_to_submit \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m _records(\n\u001b[1;32m    457\u001b[0m     t\u001b[38;5;241m.\u001b[39mOperation\u001b[38;5;241m.\u001b[39mUPSERT,\n\u001b[1;32m    458\u001b[0m     ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    463\u001b[0m     uris\u001b[38;5;241m=\u001b[39muris,\n\u001b[1;32m    464\u001b[0m ):\n\u001b[0;32m--> 465\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embedding_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    466\u001b[0m     records_to_submit\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_producer\u001b[38;5;241m.\u001b[39msubmit_embeddings(coll[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtopic\u001b[39m\u001b[38;5;124m\"\u001b[39m], records_to_submit)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/api/segment.py:803\u001b[0m, in \u001b[0;36mSegmentAPI._validate_embedding_record\u001b[0;34m(self, collection, record)\u001b[0m\n\u001b[1;32m    801\u001b[0m add_attributes_to_current_span({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollection_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m])})\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m record[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 803\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_dimension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcollection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membedding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/telemetry/opentelemetry/__init__.py:127\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m tracer, granularity\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trace_granularity \u001b[38;5;241m<\u001b[39m granularity:\n\u001b[0;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracer:\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/chromadb/api/segment.py:818\u001b[0m, in \u001b[0;36mSegmentAPI._validate_dimension\u001b[0;34m(self, collection, dim, update)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_collection_cache[\u001b[38;5;28mid\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dim\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m collection[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m!=\u001b[39m dim:\n\u001b[0;32m--> 818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidDimensionException(\n\u001b[1;32m    819\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match collection dimensionality \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdimension\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    820\u001b[0m     )\n\u001b[1;32m    821\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    822\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[0;31mInvalidDimensionException\u001b[0m: Embedding dimension 384 does not match collection dimensionality 4096"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "db_directory = \"/workspaces/myStuff/RAG01/chromadb\"\n",
    "os.makedirs(db_directory, exist_ok=True)\n",
    "\n",
    "local_repo_path = \"/workspaces/myStuff/RAG01/git-repos\"\n",
    "repos_list = [\n",
    "    {'name': 'achainflow', 'url': 'https://github.com/vcappuccio/achainflow'},\n",
    "]\n",
    "\n",
    "\n",
    "texts= update_chroma_db(repos_list, local_repo_path, db_directory)\n",
    "vectordb = Chroma.from_documents(texts, embedding=embeddings, persist_directory=db_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "retriever = vectordb.as_retriever(\n",
    "    search_type=\"mmr\",  # Also test \"similarity\"\n",
    "    search_kwargs={\"k\": 8},\n",
    ")\n",
    "\n",
    "# Define prompts\n",
    "retriever_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Given the above conversation, generate a search query to look up to get information relevant to the conversation\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "document_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer the user's questions based on the below context:\\n\\n{context}\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{chat_history}\"),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create retriever and document chains\n",
    "retriever_chain = create_history_aware_retriever(model, retriever, retriever_prompt)\n",
    "document_chain = create_stuff_documents_chain(model, document_prompt)\n",
    "\n",
    "# Create final QA chain\n",
    "qa = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code is a Python script that implements a Streamlit application that uses a chain of AI advisors to provide a comprehensive answer to a user's problem. Here's a breakdown of what the code does:\n",
      "\n",
      "1. **User Input**: The user inputs a problem or question into a text area.\n",
      "2. **Advisor Evaluation**: The user's input is processed by a series of AI advisors, each with its own model and expertise. The advisors provide their input, suggestions, and ideas related to the user's problem.\n",
      "3. **Advisor Consultation**: The code uses asynchronous programming to consult multiple advisors in a chain, where each advisor builds upon the previous one's output. The consultants are called using the `consult_advisor_async` function, which uses the Ollama API to interact with the advisors.\n",
      "4. **Final Answer**: The output from the chain of advisors is processed and consolidated into a single, comprehensive answer. This answer is then returned to the user as the final response.\n",
      "5. **Streamlit App**: The entire process is wrapped in a Streamlit application, which provides a user-friendly interface for the user to input their problem and receive the final answer.\n",
      "\n",
      "The code uses various functions and APIs, including:\n",
      "\n",
      "* `go_groq_go`: A function that sends a message to the Groq API for completion and returns the response message content.\n",
      "* `consult_advisor_async`: A function that asynchronously consults an advisor using the Ollama API and returns the advisor's response message content.\n",
      "* `get_over_a_chain_of_advisors_async`: A function that consults a chain of advisors using different models and returns the final answer.\n",
      "\n",
      "Overall, the code demonstrates a novel approach to leveraging AI advisors to provide comprehensive and insightful answers to complex problems.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the code doing?\"\n",
    "result = qa.invoke({\"input\": question})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_template = \"\"\"\n",
    "Answer the user's questions based on the below context.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
    "Use three sentences maximum and keep the answer as concise as possible:\n",
    "\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_template),\n",
    "        (\"user\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "document_chain = create_stuff_documents_chain(model, prompt)\n",
    "\n",
    "qa_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some suggestions to improve the code:\n",
      "\n",
      "1. **Consistent naming conventions**: The code uses both camelCase and underscore notation for variable and function names. It's better to stick to a single convention throughout the code. In Python, underscore notation is more commonly used.\n",
      "\n",
      "2. **Function and variable naming**: Some function and variable names are not very descriptive. For example, `go_groq_go` and `system_message3` could be renamed to something more meaningful.\n",
      "\n",
      "3. **Code repetition**: The code has a lot of repeated code blocks, especially in the `consult_advisor_async` and `get_over_a_chain_of_advisors_async` functions. Consider extracting the common logic into separate functions to reduce code duplication.\n",
      "\n",
      "4. **Error handling**: The code does not handle errors or exceptions. Consider adding try-except blocks to handle potential errors, such as network errors or API errors.\n",
      "\n",
      "5. **Documentation**: The code has some docstrings, but they could be more detailed and descriptive. Consider adding more information about what each function does, what inputs it expects, and what it returns.\n",
      "\n",
      "6. **Type hints**: The code does not use type hints, which can make it harder to understand the expected input and output types of functions. Consider adding type hints for function parameters and return types.\n",
      "\n",
      "7. **Async/await syntax**: The code uses both `async` and `await` keywords, which can be confusing. Consider using the `async/await` syntax consistently throughout the code.\n",
      "\n",
      "8. **Code organization**: The code has a mix of functions and async functions. Consider separating the synchronous and asynchronous code into separate modules or files.\n",
      "\n",
      "9. **Testing**: The code does not have any tests. Consider adding unit tests and integration tests to ensure the code works as expected.\n",
      "\n",
      "10. **Code style**: The code has inconsistent indentation and spacing. Consider using a linter and a code formatter to ensure consistent code style.\n",
      "\n",
      "Here are some specific suggestions:\n",
      "\n",
      "* Consider extracting the `advisor_evaluation` string into a separate function to make the code more modular.\n",
      "* Consider using a more descriptive name for the `messages` variable in the `consult_advisor_async` function.\n",
      "* Consider adding a `timeout` parameter to the `consult_advisor_async` function to handle potential timeouts.\n",
      "* Consider using a more descriptive name for the `final_answer` variable in the `main` function.\n",
      "\n",
      "Overall, the code is well-structured, but could benefit from some refactoring to make it more readable, maintainable, and efficient.\n"
     ]
    }
   ],
   "source": [
    "print(qa_chain.pick(\"answer\").invoke({\"input\": \"What and how can I improve this code?\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the solutions to the issues mentioned:\n",
      "\n",
      "**1. Code Duplication:**\n",
      "\n",
      "We can unify the functions `go_groq_go`, `consult_advisor_async`, and `get_over_a_chain_of_advisors_async` into a single function with parameters. Here's how you can do it:\n",
      "\n",
      "```\n",
      "async def consult_api(model, system_message, user_message):\n",
      "    \"\"\"\n",
      "    Asynchronously consult an advisor using the API and return the response message content.\n",
      "\n",
      "    Args:\n",
      "        model (str): The model to consult.\n",
      "        system_message (str): The system message to be included in the consultation.\n",
      "        user_message (str or list): The user message(s) to be included in the consultation.\n",
      "\n",
      "    Returns:\n",
      "        str: The advisor's response message content.\n",
      "    \"\"\"\n",
      "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
      "    \n",
      "    if isinstance(user_message, list):\n",
      "        messages.extend(\n",
      "            {\"role\": \"user\", \"content\": msg} if isinstance(msg, str) else msg\n",
      "            for msg in user_message\n",
      "        )\n",
      "    else:\n",
      "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
      "    \n",
      "    try:\n",
      "        response = await AsyncClient().chat(model=model, messages=messages)\n",
      "        return response['message']['content'].strip()\n",
      "    except Exception as e:\n",
      "        return f\"Error: {str(e)}\"\n",
      "```\n",
      "\n",
      "**2. Error Handling:**\n",
      "\n",
      "Error handling is added to the unified function above. It catches any exceptions and returns an error message.\n",
      "\n",
      "**3. Type Hints and Docstrings:**\n",
      "\n",
      "Type hints and docstrings are added to the unified function above.\n",
      "\n",
      "**4. Code Organization:**\n",
      "\n",
      "To better organize the code, we can separate the code into distinct modules. For example:\n",
      "\n",
      "* `api_client.py`: This module can contain the `AsyncClient` class and the unified function `consult_api`.\n",
      "* `advisor_models.py`: This module can contain the different advisor models.\n",
      "* `app.py`: This module can contain the Streamlit application.\n",
      "\n",
      "**5. asyncio Usage:**\n",
      "\n",
      "The necessity of `asyncio` depends on the requirements of your application. If you need to make concurrent API calls, then `asyncio` is a good choice. However, if you don't need concurrency, you can convert the code to synchronous operations.\n",
      "\n",
      "**6. Testing:**\n",
      "\n",
      "You should write unit tests and integration tests to verify the functionality of your code. You can use a testing framework like `pytest` to write tests. For example:\n",
      "\n",
      "```\n",
      "import pytest\n",
      "from api_client import consult_api\n",
      "\n",
      "@pytest.mark.asyncio\n",
      "async def test_consult_api():\n",
      "    model = \"llama3-70b-8192\"\n",
      "    system_message = \"Some system message\"\n",
      "    user_message = \"Some user message\"\n",
      "    response = await consult_api(model, system_message, user_message)\n",
      "    assert response is not None\n",
      "```\n",
      "\n",
      "This is just an example test. You should write more tests to cover different scenarios and edge cases.\n"
     ]
    }
   ],
   "source": [
    "def handle_query(qa_chain, input_query):\n",
    "    return qa_chain.pick(\"answer\").invoke({\"input\": input_query})\n",
    "\n",
    " \n",
    "# Detailed input query specifying the issues and requesting complete code solutions\n",
    "input_query = \"\"\"\n",
    "Please provide complete solutions for the following issues, including all necessary code:\n",
    "1. **Code Duplication**: The functions `go_groq_go`, `consult_advisor_async`, and `get_over_a_chain_of_advisors_async` are almost identical. Implement a unified function with appropriate parameters to minimize duplication.\n",
    "2. **Error Handling**: Current error management is inadequate. Integrate try-except blocks to manage potential errors like API key issues, connection interruptions, or JSON parsing errors.\n",
    "3. **Type Hints and Docstrings**: Absence of type hints and docstrings in function definitions. Add type hints for better readability and error prevention. Include docstrings to describe the functions' purposes, parameters, and expected outputs.\n",
    "4. **Code Organization**: The extensive codebase could benefit from modularization. Consider separating the code into distinct modules, such as one for the API client, another for advisor models, and a third for the Streamlit application.\n",
    "5. **asyncio Usage**: The necessity for `asyncio` is unclear. Evaluate if the code can be converted to synchronous operations for simplicity and maintainability.\n",
    "6. **Testing**: The absence of tests is a critical oversight. Develop unit and integration tests to verify functionality and detect regressions.\n",
    "\"\"\"\n",
    "\n",
    "result = handle_query(qa_chain, input_query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
